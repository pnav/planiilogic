{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "706b694d",
   "metadata": {},
   "source": [
    "# Assignment 4\n",
    "### Target date: Thursday 10/21/21 11:59pm (+5 points)\n",
    "### Due date: Sunday 10/24/21 11:59pm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d427c004",
   "metadata": {},
   "source": [
    "**Instructions:**  Complete your answers to the questions below by double-clicking on each box and writing your answers. Use \"Shift-Return\" to store your new in each answer box. Feel free to add additional notebook cells as you develop your answers. To submit, download the notebook (as .ipynb), change the file name to your team name, then upload the file to Canvas on the Assignment page. That's it!\n",
    "\n",
    "**NOTE:** You only need to upload one notebook for your group, but ***each*** group member should complete the peer evaluation. All peer evaluation feedback will remain anonymous.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10bc47b",
   "metadata": {},
   "source": [
    "**Question 1** \n",
    "\n",
    "This question uses reports of UFO sightings collected by the National UFO Reporting Center (NUFORC) and the Mutual UFO Network (MUFON). I don't recommend searching for either of those organizations :-) \n",
    "\n",
    "For this question, you will use [Pandas](https://pandas.pydata.org/), a popular Python-based data analysis and manipulation package. Pandas supports the data sorting and filtering that you did in Assignment 3 and it also integrates with other analysis packages like [Matplotlib](https://matplotlib.org/) and [Plotly](https://plotly.com/python/). Pandas data is stored primarily in one-dimensional [Series](https://pandas.pydata.org/docs/reference/series.html) and two-dimensional [DataFrame](https://pandas.pydata.org/docs/reference/frame.html) objects.\n",
    "\n",
    "Using Pandas, write code to do the following:\n",
    "* Lists the countries where sightings occurred with a count of sightings per country.\n",
    "* For sightings in the USA, list the states where sightings occurred with a count of sightings per state.\n",
    "* List the reported UFO shapes with a count of number of sightings per shape.\n",
    "* Filter the top ten US states with the most UFO sightings\n",
    "* Create a bar plot showing the number of each UFO shapes reported by each of states with the most sightings.\n",
    " \n",
    "The cells below have been started for you. Find and replace the ellipses '...' with your code that implements each solution. \n",
    "\n",
    "**Concepts:** data grouping, data retabulation, data filtering, data visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e895ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, csv, os\n",
    "import pandas as pd\n",
    "\n",
    "# Load the UFO observation data\n",
    "if not os.path.exists('ufo_location_shape.csv'):\n",
    "    url = \"https://pages.tacc.utexas.edu/~pnav/tc310/ufo_location_shape.csv\"\n",
    "    req = requests.get(url)\n",
    "    if req.ok:\n",
    "        with open('ufo_location_shape.csv','w') as fp:\n",
    "            fp.write(req.content.decode())\n",
    "    else:\n",
    "        # if you see this message, please let Paul know!\n",
    "        print(f\"TC310: ERROR - {url} returned unexpected code {req.status_code}\")\n",
    "        req.raise_for_status()\n",
    "df = pd.read_csv('ufo_location_shape.csv')\n",
    "        \n",
    "\n",
    "# should get:\n",
    "# (3646, 7)\n",
    "print(df.shape)\n",
    "print()\n",
    "\n",
    "# should get:\n",
    "# [RangeIndex(start=0, stop=3646, step=1),\n",
    "# Index(['Event.Date', 'Shape', 'Location', 'State', 'Country', 'Source', 'USA'], dtype='object')]\n",
    "print(df.axes)\n",
    "print()\n",
    "\n",
    "# should get:\n",
    "# Event.Date    3646\n",
    "# Shape         3646\n",
    "# Location      3635\n",
    "# State         3523  <-- notice this\n",
    "# Country       3642\n",
    "# Source        3646\n",
    "# USA           3646\n",
    "# dtype: int64\n",
    "print(df.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0a3a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the countries where sightings occurred with a count of sightings per country.\n",
    "# should have 42 \"countries\" listed\n",
    "\n",
    "# hint: use groupby and count methods\n",
    "\n",
    "print(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66daf6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For sightings in the USA, list the states where sightings occurred with a count of sightings per state.\n",
    "usa = ...\n",
    "print(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c970e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the reported UFO shapes with a count of number of sightings per shape.\n",
    "# should have 21 \"shapes\" listed\n",
    "print(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd13d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the top ten US states with the most UFO sightings\n",
    "top_ten = ...\n",
    "top_ten_data = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01b392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar plot showing the number of each UFO shapes reported by each of the top ten states.\n",
    "# hint: create a new DataFrame where the columns are the top ten states and the indices (rows) are the UFO shapes\n",
    "data_to_plot = ...\n",
    "\n",
    "...\n",
    "\n",
    "data_to_plot.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9105bb51",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "The [Federal Election Commission](https://www.fec.gov/) publishes data on current and previous federal election fundraising. In this question, you will again use Pandas to analyze and visualize 2022 fundraising status.\n",
    "\n",
    "For this question, you will use a recent version of the candidate summary file for all 2022 federal elections downloaded from the [FEC Bulk Downloads site](https://www.fec.gov/data/browse-data/?tab=bulk-data). The summary schema (i.e., column order and descriptions) can be found [here](https://www.fec.gov/campaign-finance-data/all-candidates-file-description/).\n",
    "\n",
    "Using Pandas and Plotly, perform the following:\n",
    "* filter state data by removing the Presidential data (state '00')\n",
    "* plot total election receipts by state\n",
    "* plot total election receipts by state for Democrats, Independents and Republicans\n",
    "* plot the difference in \"cash on-hand\" between Democrats and Republicans by state\n",
    "\n",
    "The cells below have been started for you. Find and replace the ellipses '...' with your code that implements each solution. \n",
    "\n",
    "**Concepts:** data tabluation, data filtering, data aggregation, data visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6434fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, csv, os\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "\n",
    "# Load the FEC 2022 funding data\n",
    "# download it if necessary\n",
    "if not os.path.exists('weball22.txt'):\n",
    "    url = \"https://pages.tacc.utexas.edu/~pnav/tc310/weball22.zip\"\n",
    "    req = requests.get(url)\n",
    "    if req.ok:\n",
    "        with open('weball22.zip','wb') as fp:\n",
    "            fp.write(req.content)\n",
    "        with ZipFile('weball22.zip') as zf:\n",
    "            zf.extract('weball22.txt')\n",
    "    else:\n",
    "        # if you see this message, please let Paul know!\n",
    "        print(f\"TC310: ERROR - {url} returned unexpected code {req.status_code}\")\n",
    "        req.raise_for_status()\n",
    "        \n",
    "columns = ['CAND_ID','CAND_NAME','CAND_ICI','PTY_CD','CAND_PTY_AFFILIATION','TTL_RECEIPTS','TRANS_FROM_AUTH','TTL_DISB','TRANS_TO_AUTH','COH_BOP','COH_COP','CAND_CONTRIB','CAND_LOANS','OTHER_LOANS','CAND_LOAN_REPAY','OTHER_LOAN_REPAY','DEBTS_OWED_BY','TTL_INDIV_CONTRIB','CAND_OFFICE_ST','CAND_OFFICE_DISTRICT','SPEC_ELECTION','PRIM_ELECTION','RUN_ELECTION','GEN_ELECTION','GEN_ELECTION_PRECENT','OTHER_POL_CMTE_CONTRIB','POL_PTY_CONTRIB','CVG_END_DT','INDIV_REFUNDS','CMTE_REFUNDS',]\n",
    "df = pd.read_csv('weball22.txt',delimiter='|',names=columns)\n",
    "\n",
    "# should get:\n",
    "# (2572, 30)\n",
    "print(df.shape)\n",
    "print()\n",
    "\n",
    "# should get:\n",
    "# [RangeIndex(start=0, stop=2572, step=1), Index(['CAND_ID', 'CAND_NAME', 'CAND_ICI', 'PTY_CD', 'CAND_PTY_AFFILIATION',\n",
    "#        'TTL_RECEIPTS', 'TRANS_FROM_AUTH', 'TTL_DISB', 'TRANS_TO_AUTH',\n",
    "#        'COH_BOP', 'COH_COP', 'CAND_CONTRIB', 'CAND_LOANS', 'OTHER_LOANS',\n",
    "#        'CAND_LOAN_REPAY', 'OTHER_LOAN_REPAY', 'DEBTS_OWED_BY',\n",
    "#        'TTL_INDIV_CONTRIB', 'CAND_OFFICE_ST', 'CAND_OFFICE_DISTRICT',\n",
    "#        'SPEC_ELECTION', 'PRIM_ELECTION', 'RUN_ELECTION', 'GEN_ELECTION',\n",
    "#        'GEN_ELECTION_PRECENT', 'OTHER_POL_CMTE_CONTRIB', 'POL_PTY_CONTRIB',\n",
    "#        'CVG_END_DT', 'INDIV_REFUNDS', 'CMTE_REFUNDS'],\n",
    "#       dtype='object')]\n",
    "print(df.axes)\n",
    "print()\n",
    "\n",
    "# should get:\n",
    "# CAND_ID                   2572\n",
    "# CAND_NAME                 2572\n",
    "# CAND_ICI                  2525\n",
    "# PTY_CD                    2572\n",
    "# CAND_PTY_AFFILIATION      2572\n",
    "# TTL_RECEIPTS              2572\n",
    "# TRANS_FROM_AUTH           2572\n",
    "# TTL_DISB                  2572\n",
    "# TRANS_TO_AUTH             2572\n",
    "# COH_BOP                   2572\n",
    "# COH_COP                   2572\n",
    "# CAND_CONTRIB              2572\n",
    "# CAND_LOANS                2572\n",
    "# OTHER_LOANS               2572\n",
    "# CAND_LOAN_REPAY           2572\n",
    "# OTHER_LOAN_REPAY          2572\n",
    "# DEBTS_OWED_BY             2572\n",
    "# TTL_INDIV_CONTRIB         2572\n",
    "# CAND_OFFICE_ST            2572\n",
    "# CAND_OFFICE_DISTRICT      2572\n",
    "# SPEC_ELECTION                0\n",
    "# PRIM_ELECTION                0\n",
    "# RUN_ELECTION                 0\n",
    "# GEN_ELECTION                 0\n",
    "# GEN_ELECTION_PRECENT         0\n",
    "# OTHER_POL_CMTE_CONTRIB    2572\n",
    "# POL_PTY_CONTRIB           2572\n",
    "# CVG_END_DT                2572\n",
    "# INDIV_REFUNDS             2572\n",
    "# CMTE_REFUNDS              2572\n",
    "# dtype: int64\n",
    "print(df.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df085be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove Presidential data (state '00')\n",
    "# hint: create a new DataFrame with an index operator filter\n",
    "state_data = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a969328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame with total receipts by state using groupby and sum operators\n",
    "total_receipts = ...\n",
    "\n",
    "# Index(['AK', 'AL', 'AR', 'AS', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA',\n",
    "#        'GU', 'HI', 'IA', 'ID', 'IL', 'IN', 'KS', 'KY', 'LA', 'MA', 'MD', 'ME',\n",
    "#        'MI', 'MN', 'MO', 'MP', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH', 'NJ', 'NM',\n",
    "#        'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'PR', 'RI', 'SC', 'SD', 'TN', 'TX',\n",
    "#        'UT', 'VA', 'VI', 'VT', 'WA', 'WI', 'WV', 'WY'],\n",
    "#       dtype='object', name='CAND_OFFICE_ST')\n",
    "print(total_receipts.index)\n",
    "print()\n",
    "\n",
    "# [2.64522802e+06 1.27492469e+07 5.52614271e+06 3.30000000e+03\n",
    "#  2.52764655e+07 6.28003649e+07 9.39918695e+06 4.81012950e+06\n",
    "#  7.53016900e+04 9.34779220e+05 4.35234276e+07 8.26865311e+07\n",
    "#  1.15000000e+04 1.20249640e+06 6.91695637e+06 1.63452379e+06\n",
    "#  1.89811639e+07 1.03858661e+07 4.54196917e+06 1.01398307e+07\n",
    "#  1.75380119e+07 7.76184753e+06 6.69692784e+06 2.32000004e+06\n",
    "#  1.22015190e+07 7.02382852e+06 1.54871082e+07 7.00000000e+03\n",
    "#  1.30134854e+06 2.67689239e+06 1.73525449e+07 7.44663920e+05\n",
    "#  1.89481852e+06 8.44078852e+06 1.32066099e+07 6.24823232e+06\n",
    "#  1.02988450e+07 4.81132540e+07 4.07751460e+07 3.96622906e+06\n",
    "#  6.12746291e+06 2.90436532e+07 4.75926000e+04 1.74588295e+06\n",
    "#  2.00623532e+07 2.25146142e+06 4.92909954e+06 3.74025146e+07\n",
    "#  3.86566690e+06 8.10997595e+06 2.21201020e+05 8.96540265e+06\n",
    "#  1.28699138e+07 1.16025489e+07 5.06341576e+06 4.79026833e+06]\n",
    "print(total_receipts.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa10eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=go.Choropleth(\n",
    "    locations=total_receipts.index, # Spatial coordinates\n",
    "    z = total_receipts.values, # Data to be color-coded\n",
    "    locationmode = 'USA-states', # set of locations match entries in `locations`\n",
    "    colorscale = 'Greens',\n",
    "    colorbar_title = \"Millions USD\",\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text = '2022 Total Federal Election Receipts by State',\n",
    "    geo_scope='usa', # limit map scope to USA\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623bb0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data subsets for Republican (GOP), Democratic and Independent candidates\n",
    "gop = ...\n",
    "dem = ...\n",
    "ind = ...\n",
    "\n",
    "# use groupby and sum to calculate total receipts by state\n",
    "gop_receipts = ...\n",
    "dem_receipts = ...\n",
    "ind_receipts = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937a719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=go.Choropleth(\n",
    "    locations=gop_receipts.index, # Spatial coordinates\n",
    "    z = gop_receipts.values, # Data to be color-coded\n",
    "    locationmode = 'USA-states', # set of locations match entries in `locations`\n",
    "    colorscale = 'Reds',\n",
    "    colorbar_title = \"Millions USD\",\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text = '2022 Republican Federal Election Receipts by State',\n",
    "    geo_scope='usa', # limit map scope to USA\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4a80f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=go.Choropleth(\n",
    "    locations=dem_receipts.index, # Spatial coordinates\n",
    "    z = dem_receipts.values, # Data to be color-coded\n",
    "    locationmode = 'USA-states', # set of locations match entries in `locations`\n",
    "    colorscale = 'Blues',\n",
    "    colorbar_title = \"Millions USD\",\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text = '2022 Democratic Federal Election Receipts by State',\n",
    "    geo_scope='usa', # limit map scope to USA\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9093d688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=go.Choropleth(\n",
    "    locations=ind_receipts.index, # Spatial coordinates\n",
    "    z = ind_receipts.values, # Data to be color-coded\n",
    "    locationmode = 'USA-states', # set of locations match entries in `locations`\n",
    "    colorscale = 'Purples',\n",
    "    colorbar_title = \"Millions USD\",\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text = '2022 Independent Federal Election Receipts by State',\n",
    "    geo_scope='usa', # limit map scope to USA\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f441b71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the difference in cash on hand at the close of the period between Democrat and Republican candidates by state\n",
    "# hint: subtract gop_coh from dem_coh to get the data to align with the blue/red colormap\n",
    "\n",
    "gop_coh = ...\n",
    "dem_coh = ...\n",
    "coh_diff = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c570af86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "fig = go.Figure(data=go.Choropleth(\n",
    "    locations=coh_diff.index, # Spatial coordinates\n",
    "    z = coh_diff.values, # Data to be color-coded\n",
    "    locationmode = 'USA-states', # set of locations match entries in `locations`\n",
    "    colorscale = 'rdbu',\n",
    "    colorbar_title = \"Millions USD\",\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text = '2022 Difference in Cash on Hand (+DEM / -GOP)',\n",
    "    geo_scope='usa', # limit map scope to USA\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71471b6",
   "metadata": {},
   "source": [
    "**Question 3**\n",
    "\n",
    "For this question, you will use an image classification neural network that attempts to distinguish dogs and cats in images. This question uses the code from the [Keras Image Classification from Scratch](https://keras.io/examples/vision/image_classification_from_scratch/) example and [pet image data](https://www.kaggle.com/karakaggle/kaggle-cat-vs-dog-dataset) collected by [Microsoft](https://www.microsoft.com/en-us/download/details.aspx?id=54765).\n",
    "\n",
    "Training the neural net on the full dataset can take a _long_ time, particularly on a laptop. The training cells are included below for reference, but are not needed (unless you want to give training a try!). The download contains three pre-trained networks:\n",
    "\n",
    "* `catdog_classifier_20000i_50e.model` trained on 20_000 images over 50 epochs\n",
    "* `catdog_classifier_2000i_30e.model` trained on  2_000 images over 30 epochs\n",
    "* `catdog_classifier_200i_10e.model` trained on    200 images over 10 epochs\n",
    "\n",
    "Using each of the three networks, run them against the images in the `Validation` directory and calculate the average confidence for each correctly classified image and note which images are misclassified.\n",
    "\n",
    "The cells below have been started for you. Find and replace the ellipses '...' with your code that implements each solution. \n",
    "\n",
    "**Concepts:** image classification, training data, validation data, training quality \n",
    "\n",
    "*Ponderable*: why did the network(s) miss on the images? Any commonalities among the images that were misclassified?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdc88ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to download the image files and pre-trained networks\n",
    "# code modified from https://keras.io/examples/vision/image_classification_from_scratch/\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import os, requests\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# Load the Pet Images data\n",
    "# download it if necessary\n",
    "if not os.path.exists('Validation'):\n",
    "    url = \"https://pages.tacc.utexas.edu/~pnav/tc310/catdog.zip\"\n",
    "    req = requests.get(url)\n",
    "    if req.ok:\n",
    "        with open('catdog.zip','wb') as fp:\n",
    "            fp.write(req.content)\n",
    "        with ZipFile('catdog.zip') as zf:\n",
    "            zf.extractall()\n",
    "    else:\n",
    "        # if you see this message, please let Paul know!\n",
    "        print(f\"TC310: ERROR - {url} returned unexpected code {req.status_code}\")\n",
    "        req.raise_for_status()\n",
    "\n",
    "    # filter out corrupted images\n",
    "    num_skipped = 0\n",
    "    for folder_name in (\"Cat\", \"Dog\"):\n",
    "        folder_path = os.path.join(\"Pet_20000\", folder_name)\n",
    "        for fname in os.listdir(folder_path):\n",
    "            fpath = os.path.join(folder_path, fname)\n",
    "            try:\n",
    "                fobj = open(fpath, \"rb\")\n",
    "                is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n",
    "            finally:\n",
    "                fobj.close()\n",
    "\n",
    "            if not is_jfif:\n",
    "                num_skipped += 1\n",
    "                # Delete corrupted image\n",
    "                os.remove(fpath)\n",
    "\n",
    "    print(\"Deleted %d images\" % num_skipped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fc17de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE from https://keras.io/examples/vision/image_classification_from_scratch/\n",
    "# DO NOT RUN\n",
    "# build training and testing subsets\n",
    "# \n",
    "\n",
    "image_size = (180, 180)\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"Pet_20000\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"Pet_20000\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139b8607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE from https://keras.io/examples/vision/image_classification_from_scratch/\n",
    "# \n",
    "# visualize data samples\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(int(labels[i]))\n",
    "        plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ca13f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE from https://keras.io/examples/vision/image_classification_from_scratch/\n",
    "#\n",
    "# augment dataset with image pertubations\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        augmented_images = data_augmentation(images)\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c775ba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE from https://keras.io/examples/vision/image_classification_from_scratch/\n",
    "# DO NOT RUN\n",
    "# make the image classification model\n",
    "\n",
    "def make_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    # Image augmentation block\n",
    "    x = data_augmentation(inputs)\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Rescaling(1.0 / 255)(x)\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [128, 256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes\n",
    "\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model = make_model(input_shape=image_size + (3,), num_classes=2)\n",
    "keras.utils.plot_model(model, show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99554838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE from https://keras.io/examples/vision/image_classification_from_scratch/\n",
    "# DO NOT RUN\n",
    "# train the model\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,\n",
    ")\n",
    "\n",
    "model.save(\"catdog_classifier.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2cb45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE from https://keras.io/examples/vision/image_classification_from_scratch/\n",
    "# DO NOT RUN\n",
    "# example to run a trained model against a single image\n",
    "\n",
    "if os.path.exists(\"catdog_classifier.model\"):\n",
    "    model = keras.models.load_model(\"catdog_classifier.model\")\n",
    "\n",
    "img = keras.preprocessing.image.load_img(\n",
    "    \"Pet_20000/Cat/6779.jpg\", target_size=image_size\n",
    ")\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = predictions[0]\n",
    "print(\n",
    "    \"This image is %.2f percent cat and %.2f percent dog.\"\n",
    "    % (100 * (1 - score), 100 * score)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91abffb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the three pre-trained models against the validation image set\n",
    "# hint: see file loading cell for insight on how to iterate over all validation images\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "image_size = (180, 180)\n",
    "model_files = (\"catdog_classifier_20000i_50e.model\",\n",
    "               \"catdog_classifier_2000i_30e.model\",\n",
    "               \"catdog_classifier_200i_10e.model\")\n",
    "for model_file in model_files:\n",
    "    model = keras.models.load_model(model_file)\n",
    "    img = keras.preprocessing.image.load_img(\n",
    "        \"Pet_20000/Cat/6779.jpg\", target_size=image_size\n",
    "    )\n",
    "    img_array = keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "    score = predictions[0]\n",
    "    print(\n",
    "        \"This image is %.2f percent cat and %.2f percent dog.\"\n",
    "        % (100 * (1 - score), 100 * score)\n",
    "    )\n",
    "# example output:\n",
    "# Stats for catdog_classifier_20000i_50e.model:\n",
    "# \tScoring average for cat: 98%\n",
    "# \tMisclassified files:\n",
    "# \t\tValidation/Cat/10029.jpg\n",
    "# \tScoring average for dog: 96%\n",
    "# \tMisclassified files:\n",
    "# \t\tValidation/Dog/10016.jpg\n",
    "# \t\tValidation/Dog/10024.jpg\n",
    "# \t\tValidation/Dog/10052.jpg\n",
    "# \t\tValidation/Dog/10085.jpg\n",
    "# \t\tValidation/Dog/10092.jpg\n",
    "# Stats for catdog_classifier_2000i_30e.model:\n",
    "# \tScoring average for cat: 97%\n",
    "# \tMisclassified files:\n",
    "# \t\tValidation/Cat/10013.jpg\n",
    "# \t\tValidation/Cat/10022.jpg\n",
    "# \t\tValidation/Cat/10026.jpg\n",
    "# \t\tValidation/Cat/10056.jpg\n",
    "# \t\tValidation/Cat/10058.jpg\n",
    "# \t\tValidation/Cat/10059.jpg\n",
    "# \t\tValidation/Cat/10069.jpg\n",
    "# \t\tValidation/Cat/10090.jpg\n",
    "# \t\tValidation/Cat/10099.jpg\n",
    "# \tScoring average for dog: 99%\n",
    "# \tMisclassified files:\n",
    "# \t\tValidation/Dog/10024.jpg\n",
    "# \t\tValidation/Dog/10072.jpg\n",
    "# Stats for catdog_classifier_200i_10e.model:\n",
    "# \tScoring average for cat: 95%\n",
    "# \tMisclassified files:\n",
    "# \t\tValidation/Cat/10003.jpg\n",
    "# \t\tValidation/Cat/10013.jpg\n",
    "# \t\tValidation/Cat/10015.jpg\n",
    "# \t\tValidation/Cat/10016.jpg\n",
    "# \t\tValidation/Cat/10018.jpg\n",
    "# \t\tValidation/Cat/10022.jpg\n",
    "# \t\tValidation/Cat/10024.jpg\n",
    "# \t\tValidation/Cat/10025.jpg\n",
    "# \t\tValidation/Cat/10026.jpg\n",
    "# \t\tValidation/Cat/10027.jpg\n",
    "# \t\tValidation/Cat/10029.jpg\n",
    "# \t\tValidation/Cat/10032.jpg\n",
    "# \t\tValidation/Cat/10035.jpg\n",
    "# \t\tValidation/Cat/10042.jpg\n",
    "# \t\tValidation/Cat/10043.jpg\n",
    "# \t\tValidation/Cat/10048.jpg\n",
    "# \t\tValidation/Cat/10051.jpg\n",
    "# \t\tValidation/Cat/10053.jpg\n",
    "# \t\tValidation/Cat/10056.jpg\n",
    "# \t\tValidation/Cat/10058.jpg\n",
    "# \t\tValidation/Cat/10059.jpg\n",
    "# \t\tValidation/Cat/10061.jpg\n",
    "# \t\tValidation/Cat/10067.jpg\n",
    "# \t\tValidation/Cat/10069.jpg\n",
    "# \t\tValidation/Cat/10074.jpg\n",
    "# \t\tValidation/Cat/10079.jpg\n",
    "# \t\tValidation/Cat/10081.jpg\n",
    "# \t\tValidation/Cat/10082.jpg\n",
    "# \t\tValidation/Cat/10083.jpg\n",
    "# \t\tValidation/Cat/10086.jpg\n",
    "# \t\tValidation/Cat/10089.jpg\n",
    "# \t\tValidation/Cat/10090.jpg\n",
    "# \t\tValidation/Cat/10093.jpg\n",
    "# \t\tValidation/Cat/10094.jpg\n",
    "# \t\tValidation/Cat/10095.jpg\n",
    "# \tScoring average for dog: 99%\n",
    "# \tMisclassified files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086e74d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
